import javax.net.ssl.*
import groovyx.net.http.RESTClient
import static groovyx.net.http.ContentType.JSON
import groovy.json.JsonSlurper

buildscript {
    repositories {
        mavenCentral()
        jcenter()
    }
    dependencies {
        classpath 'de.undercouch:gradle-download-task:3.0'
        classpath 'org.codehaus.groovy.modules.http-builder:http-builder:0.7.1'
    }
}

plugins { 
    id 'java' 
    id "de.undercouch.download" version "3.0.0"
}

import de.undercouch.gradle.tasks.download.Download

Properties props = new Properties()
props.load(new FileInputStream("$projectDir/../../connection.properties"))

def host = props.elasticsearch_host
def port = props.elasticsearch_port
def user = props.elasticsearch_user
def pass = props.elasticsearch_pass

def path = "test-${new Date().getTime()}"

def slurper = new JsonSlurper()
def vcaptext = file('../../vcap.json').text
def cluster_master_url = slurper.parseText( vcaptext ).credentials.cluster_master_url
assert cluster_master_url != null

repositories {
    mavenCentral()
    jcenter()
}

task('SetupLibs', type: Download) {
    src 'http://repo1.maven.org/maven2/org/elasticsearch/elasticsearch-spark_2.10/2.3.1/elasticsearch-spark_2.10-2.3.1.jar'
    dest buildDir
    acceptAnyCertificate true
    onlyIfNewer true
    quiet true
}

task("DeleteOutput", type:Delete) {
   delete fileTree('./') {
        include '**/*.log'
        include '**/stderr_*'
        include '**/stdout_*'
    }
}

task('CreateTruststore') << {

    // Download the elasticsearch server's certificate and CA certificates and import them into a truststore
    // Elasticsearch will use the truststore to verify the server it is connecting to.  See export_to_elasticsearch.py
    // script for the `es.net.ssl*` configration parameters.

    // In a production environment, the truststore would probaly be created manually after veriying the certificate chain
    // for authenticity.

    delete('./ca_certificate*')
    delete('./es_certificate*')
    delete('./truststore.jks')
    delete('./truststore.jar')

    def certs = []

    def trustManager = [
        checkClientTrusted: { chain, authType ->  },
        checkServerTrusted: { chain, authType -> certs.push(chain[0]) },
        getAcceptedIssuers: { null }
    ] as X509TrustManager

    def context = SSLContext.getInstance("TLS")
    context.init(null, [trustManager] as TrustManager[], null)
    context.socketFactory.createSocket(host, port as int).with {
        addHandshakeCompletedListener( 
            [ 
                handshakeCompleted: { event -> certs.addAll(event.getPeerCertificates()) }   
            ] as HandshakeCompletedListener
        )
        startHandshake()
        close()
    }

    // This is required to prevent a ConcurrentModificationException when iterating
    certs = certs.asImmutable()

    certs.eachWithIndex { cert, idx ->

        (new File("${projectDir}/es_certificate_${idx}")).text = 
                   "-----BEGIN CERTIFICATE-----\n" + 
                   "${cert.encoded.encodeBase64(true)}" +
                   "-----END CERTIFICATE-----"

        ant.exec(executable: 'keytool', dir:'./') {
            arg(line: "-import -trustcacerts -alias es_certificate_${idx} -file ./es_certificate_${idx} -keystore ./truststore.jks -storepass mypassword -noprompt")
        }
    }

    ant.exec(executable: 'jar', dir:'./') {
        arg(line: '-cf truststore.jar truststore.jks')
    }
}

task('ExamplePush') {

    dependsOn DeleteOutput, CreateTruststore, SetupLibs

    doLast {

        def cmd = ["../../spark-submit.sh",
                               "--vcap", "../../vcap.json",
                               "--deploy-mode", "cluster",
                               "--master", "${cluster_master_url}",
                               "--jars", "./truststore.jar,./build/elasticsearch-spark_2.10-2.3.1.jar",
                               "./export_to_elasticsearch.py",
                                   "'${host}'",
                                   "'${port}'",
                                   "'${user}'",
                                   "'${pass}'",
                                   "'${path}'"]

        println cmd.join(" ") // print out command executed for debugging purposes

        exec {
            commandLine cmd
        }

        // verify document was created
        def client = new RESTClient( "https://${host}:${port}/")
        client.ignoreSSLIssues()
        client.headers['Authorization'] = 'Basic ' + "${user}:${pass}".getBytes('iso-8859-1').encodeBase64()

        def resp = client.get( 
                        path : "spark/${path}/_count", 
                        requestContentType : 'application/json'
                        )
        assert resp.status == 200
        assert resp.data.count == 2

        println "\nSUCCESS >> Successfully exported a document to Elasticsearch"
    }
}

task('ExamplePull') {

    // we need to run ExamplePush to create some data in ElasticSearch that 
    // we will import with this task, so we depend on ExamplePush
   dependsOn ExamplePush

    doLast {
        def cmd = ["../../spark-submit.sh",
                               "--vcap", "../../vcap.json",
                               "--deploy-mode", "cluster",
                               "--master", "${cluster_master_url}",
                               "--jars", "./truststore.jar,./build/elasticsearch-spark_2.10-2.3.1.jar",
                               "./import_from_elasticsearch.py",
                                   "'${host}'",
                                   "'${port}'",
                                   "'${user}'",
                                   "'${pass}'",
                                   "'${path}'"]

        println cmd.join(" ") // print out command executed for debugging purposes

        exec {
            commandLine cmd
        }

         println "\nSUCCESS >> Successfully imported a document to Elasticsearch"
    }
}

task('Example') {
    dependsOn ExamplePush, ExamplePull
}
